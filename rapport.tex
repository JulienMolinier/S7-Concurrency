\documentclass[12pt,oneside,a4paper]{article}
\usepackage[table]{xcolor}
\usepackage{graphicx}
\usepackage{bookmark}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{hyperref}

\hypersetup{
    colorlinks=false,
    linktoc=all,
}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\pagestyle{fancy}
\cfoot{\thepage}
\fancyhead{}
\fancyhead[R]{\leftmark}

\begin{document}
\title{%
  Rapport \\Gestion de la Concurrence}

\author{LERAS - MOLINIER}
\date{21 décembre 2019}
\maketitle
\paragraph{}
\paragraph{}
\section{Introduction}
\paragraph{}
Ce rapport rend compte d'un projet visant à étudier les contraintes de la programmation concurrente liées au parallélisme et 
aux accès concurrents sur les données. Au travers de différents scénarios nous verrons quelles solutions
peuvent être apportées en Python.

\section{Principe de fonctionnement des algorithmes}

\subsection{Scénario 0 : thread unique}
\paragraph{}

\begin{algorithm}[H]
  \caption{Scénario 0}\label{euclid}
  \begin{algorithmic}[1]
  \Procedure{algorithm0}{}
  \BState $\textit{people} \gets \text{sorted(people, key=lambda x: (pow(x[0], 2) + pow(x[1], 2)))}$
  \BState \emph{while len(people) != 0}:
  \For {p in people}
  \If {p can move outside }
  \State {people.pop(p)}
  \EndIf
  \If {p can move diagonally }
  \State {move}
  \EndIf
  \If {p can move horizontally }
  \State {move}
  \EndIf
  \If {p can move vertically }
  \State {move}
  \EndIf
  \EndFor
  \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsection{Scénario 1 : une thread par personnes}
\paragraph{}

\begin{algorithm}[H]
  \caption{Scénario 1}\label{euclid}
  \begin{algorithmic}[1]
  \Procedure{algorithm1}{}
  \BState $\textit{lock} \gets \text{Lock()}$
  \BState $\textit{tList} \gets \text{[]}$
  \For{p in people}
      \State{tList.append(Thread(target=GoToExit, args=(p, lock)))}
  \EndFor
  \For{t in tList}
      \State{t.start()}
  \EndFor
  \For{thread in tList}
      \State{thread.join()}
  \EndFor
  \EndProcedure
  \end{algorithmic}
\end{algorithm}

\paragraph{}
La méthode \textit{GoToExit()} exécute la même logique que le pseudo-code du scénario 0 en
cherchant un déplacement possible. La différence est qu'avant d'effectuer cette recherche il faut faire
\textit{lock.acquire()} et après avoir bougé faire \textit{lock.release()} afin de protéger
la liste et d'éviter qu'un autre thread vienne prendre la place trouvée.

\subsection{Scénario 2 : 4 threads}
\paragraph{}

\begin{algorithm}[H]
  \caption{Scénario 2}\label{euclid}
  \begin{algorithmic}[1]
  \Procedure{algorithm2}{}
  \BState $\textit{tList} \gets \text{[]}$
  \For{i in range(1,4)}
      \State{tList.append(Thread(target=subAlgorithm2, args=(i,)))}
  \EndFor
  \For{t in tList}
      \State{t.start()}
  \EndFor
  \For{thread in tList}
      \State{thread.join()}
  \EndFor
  \EndProcedure
  \end{algorithmic}
\end{algorithm}

\paragraph{}
La méthode \textit{subAlgorithm2()} s'occupe selon l'entier reçu de travailler sur l'une des 4 zones fraichement crées. Tout comme avec le scénario 1
il faut s'assurer de prendre les verrous avant chaque recherche et de les rendre après chaque déplacement.
La particularité ici est qu'il faut parfois prendre 2 verrous lorsque la personne change de zone et donc
change de liste.

\section{Fonctionnement des bibliothèques utilisés}

\subsection{Bibliothèque threading.Thread}
\paragraph{}
Cette bibliothèque Python permet l'implémentation du parallélisme grâce à l'utilisation de thread (multithreading).
Le problème est que le GIL (Global Interpreter Lock) réduit fortement l'utilité des threads en Python
car il ne permet l'exécution que d'un seul thread natif à la fois. Cela permet d'augmenter fortement les
performances des programmes monothread qui sont bien plus répandu.
\paragraph{}
Il semble donc que le GIL tue le multithreading Python mais pas tout à fait. Il empêche généralement de profiter
de plusieurs coeurs sur une seule machine mais permet de profiter de la latence entre les entrées/sorties.
\paragraph{}
Les scénarios qui vont suivre permettront peut-être de montrer le "faux" parallélisme du multithreading Python.

\subsection{Librairie threading.Lock}
\paragraph{}
La bibliothèque threading de Python fournit un mécanisme de verrouillage
simple qui permet de synchroniser les threads. Ce système
comprend 2 méthodes. La méthode \textit{acquire()} permet de prendre le vérrou et de 
forcer les autres threads à attendre que celui-ci soit libéré par la méthode 
\textit{release()}.

\section{Analyse des performances}
\paragraph{}
Afin de mesurer les performances des algorithmes, le paramètre -m permet de 
donner le temps moyen que met la foule à sortir du terrain. On reproduit 5 fois
l'algorithme et on supprime les 2 valeurs extrêmes pour obtenir un résultat cohérent.
Ainsi ce résultat n'est pas sensible au temps d'échauffement du processeur et
les performances plus stables.

\subsection{Scénario 0 : thread unique}
\paragraph{}
Voici le tableau des performances du scénario 0 :

\begin{table}[h]
  \centering
  \small
  \begin{tabular}{llllllllll}
    \hline
    \multicolumn{1}{|l|}{\textbf{Taille de la foule}}                     & \multicolumn{1}{l|}{$2^1$} & \multicolumn{1}{l|}{$2^2$} & \multicolumn{1}{l|}{$2^3$} & \multicolumn{1}{l|}{$2^4$} & \multicolumn{1}{l|}{$2^5$} & \multicolumn{1}{l|}{$2^6$} & \multicolumn{1}{l|}{$2^7$} & \multicolumn{1}{l|}{$2^8$} & \multicolumn{1}{l|}{$2^9$} \\ \hline
    \multicolumn{1}{|l|}{\textbf{Temps execution (ms)}} & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{3}  & \multicolumn{1}{l|}{7}  & \multicolumn{1}{l|}{16}  & \multicolumn{1}{l|}{38}  & \multicolumn{1}{l|}{122}  & \multicolumn{1}{l|}{390}  & \multicolumn{1}{l|}{1451}  \\ \hline
    \multicolumn{1}{|l|}{\textbf{Temps CPU (ms)}}    & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{3}  & \multicolumn{1}{l|}{7}  & \multicolumn{1}{l|}{16}  & \multicolumn{1}{l|}{38}  & \multicolumn{1}{l|}{122}  & \multicolumn{1}{l|}{390}  & \multicolumn{1}{l|}{1449}  \\ \hline
                                                                          &                        &                        &                        &                        &                        &                        &                        &                        &                       
    \end{tabular}
  \caption{Performances scénario 0}
  \label{Performances scénario 0}
\end{table}

\paragraph{}
Les résultats ci-dessus montrent que le temps d'exécution de l'algorithme est très similaire au temps d'
utilisation du CPU. Cela n'est pas surprenant car cet algorithme n'utilise pas de parallélisme. Les 
calculs ne sont réalisés que par un seul thread du processus main.

\subsection{Scénario 1 : une thread par personnes}
\paragraph{}
Voici le tableau des performances du scénario 1 :

\begin{table}[h]
  \centering
  \small
  \begin{tabular}{llllllllll}
    \hline
    \multicolumn{1}{|l|}{\textbf{Taille de la foule}}                     & \multicolumn{1}{l|}{$2^1$} & \multicolumn{1}{l|}{$2^2$} & \multicolumn{1}{l|}{$2^3$} & \multicolumn{1}{l|}{$2^4$} & \multicolumn{1}{l|}{$2^5$} & \multicolumn{1}{l|}{$2^6$} & \multicolumn{1}{l|}{$2^7$} & \multicolumn{1}{l|}{$2^8$} & \multicolumn{1}{l|}{$2^9$} \\ \hline
    \multicolumn{1}{|l|}{\textbf{Temps execution (ms)}} & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{2}  & \multicolumn{1}{l|}{7}  & \multicolumn{1}{l|}{22}  & \multicolumn{1}{l|}{59}  & \multicolumn{1}{l|}{164}  & \multicolumn{1}{l|}{730}  & \multicolumn{1}{l|}{6248}  & \multicolumn{1}{l|}{86753}  \\ \hline
    \multicolumn{1}{|l|}{\textbf{Temps CPU (ms)}}    & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{3}  & \multicolumn{1}{l|}{7}  & \multicolumn{1}{l|}{32}  & \multicolumn{1}{l|}{85}  & \multicolumn{1}{l|}{236}  & \multicolumn{1}{l|}{1012}  & \multicolumn{1}{l|}{8101}  & \multicolumn{1}{l|}{102378}  \\ \hline
                                                                          &                        &                        &                        &                        &                        &                        &                        &                        &                       
    \end{tabular}
  \caption{Performances scénario 1}
  \label{Performances scénario 1}
\end{table}

\paragraph{}
Tout d'abord le temps d'utilisation CPU a fortement augmenté avec ce deuxième algorithme. Il dépasse même
le temps d'exécution ce qui n'est pas étonnant car celui-ci utilise autant de threads que de personnes il
y a donc des calculs qui s'effectuent en parallèle. Par contre afin d'assurer la cohérence lors d'une recherche
d'un déplacement possible et le déplacement en lui-même la liste est protégée par un verrou. Comme tous les
threads tentent d'accéder à la même liste le temps d'attente pour prendre le verrou augmente fortement avec le nombre de personnes.

\subsection{Scénario 2 : 4 threads}
\paragraph{}
Voici le tableau des performances du scénario 2 :

\begin{table}[h]
  \centering
  \small
  \begin{tabular}{llllllllll}
  \hline
  \multicolumn{1}{|l|}{\textbf{Taille de la foule}}                     & \multicolumn{1}{l|}{$2^1$} & \multicolumn{1}{l|}{$2^2$} & \multicolumn{1}{l|}{$2^3$} & \multicolumn{1}{l|}{$2^4$} & \multicolumn{1}{l|}{$2^5$} & \multicolumn{1}{l|}{$2^6$} & \multicolumn{1}{l|}{$2^7$} & \multicolumn{1}{l|}{$2^8$} & \multicolumn{1}{l|}{$2^9$} \\ \hline
  \multicolumn{1}{|l|}{\textbf{Temps execution (ms)}} & \multicolumn{1}{l|}{60}  & \multicolumn{1}{l|}{64}  & \multicolumn{1}{l|}{72}  & \multicolumn{1}{l|}{163}  & \multicolumn{1}{l|}{295}  & \multicolumn{1}{l|}{1099}  & \multicolumn{1}{l|}{1177}  & \multicolumn{1}{l|}{1748}  & \multicolumn{1}{l|}{4379}  \\ \hline
  \multicolumn{1}{|l|}{\textbf{Temps CPU (ms)}}    & \multicolumn{1}{l|}{57}  & \multicolumn{1}{l|}{64}  & \multicolumn{1}{l|}{72}  & \multicolumn{1}{l|}{163}  & \multicolumn{1}{l|}{297}  & \multicolumn{1}{l|}{1102}  & \multicolumn{1}{l|}{1183}  & \multicolumn{1}{l|}{1759}  & \multicolumn{1}{l|}{4424}  \\ \hline
                                                                        &                        &                        &                        &                        &                        &                        &                        &                        &                       
  \end{tabular}
  \caption{Performances scénario 2}
  \label{Performances scénario 2}
\end{table}

\paragraph{}
Pour ce dernier scénario le temps d'utilisation CPU est légèrement supérieur au temps d'exécution. De 
plus le temps d'exécution reste bien supérieur à celui du scénario 1. En effet prendre et rendre un verrou
sont des opérations coûteuses et le découpage en 4 zones ne solutionne pas le problème de bouchon près de la sortie.

\section{Conclusion}
\paragraph{}
Pour conclure, l'utilisation du parallélisme et du multithreading python n'est pas forcément synonyme
de meilleures performances. Les scénarios précédents montrent clairement qu'assurer la protection
et la cohérence des données entre les différents calculs sont des opérations coûteuses qui impactent lourdement
les performances.
\end{document}