\documentclass[12pt,oneside,a4paper]{article}
\usepackage[table]{xcolor}
\usepackage{graphicx}
\usepackage{bookmark}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{hyperref}

\hypersetup{
    colorlinks=false,
    linktoc=all,
}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\pagestyle{fancy}
\cfoot{\thepage}
\fancyhead{}
\fancyhead[R]{\leftmark}
\renewcommand*\contentsname{Sommaire}

\begin{document}
\title{%
  Rapport \\Gestion de la Concurrence}

\author{LERAS - MOLINIER}
\date{21 décembre 2019}
\maketitle
\newpage

\tableofcontents
\newpage

\section{Principe de fonctionnement des algorithmes}

\subsection{Scénario 0 : thread unique}
\paragraph{}

\begin{algorithm}
  \caption{Scénario 0}\label{euclid}
  \begin{algorithmic}[1]
  \Procedure{algorithm0}{}
  \BState $\textit{people} \gets \text{sorted(people, key=lambda x: (pow(x[0], 2) + pow(x[1], 2)))}$
  \BState \emph{while len(people) != 0}:
  \For {p in people}
  \If {p can move outside }
  \State {people.pop(p)}
  \EndIf
  \If {p can move diagonally }
  \State {move}
  \EndIf
  \If {p can move horizontally }
  \State {move}
  \EndIf
  \If {p can move vertically }
  \State {move}
  \EndIf
  \EndFor
  \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsection{Scénario 1 : une thread par personnes}
\paragraph{}

\begin{algorithm}
  \caption{Scénario 1}\label{euclid}
  \begin{algorithmic}[1]
  \Procedure{algorithm1}{}
  \BState $\textit{lock} \gets \text{Lock()}$
  \BState $\textit{tList} \gets \text{[]}$
  \For{p in people}
      \State{tList.append(Thread(target=GoToExit, args=(p, lock)))}
  \EndFor
  \For{t in tList}
      \State{t.start()}
  \EndFor
  \For{thread in tList}
      \State{thread.join()}
  \EndFor
  \EndProcedure
  \end{algorithmic}
\end{algorithm}

\paragraph{}
La méthode \textit{GoToExit()} execute la même logique que le pseudo code du scénario 0 en
cherchant un déplacement possible. La différence est que avant d'effectuer cette recherche il faut faire
\textit{lock.acquire()} et après avoir bougé faire \textit{lock.release()}.

\subsection{Scénario 2 : 4 threads}
\paragraph{}

\begin{algorithm}
  \caption{Scénario 2}\label{euclid}
  \begin{algorithmic}[1]
  \Procedure{algorithm2}{}
  \BState $\textit{tList} \gets \text{[]}$
  \For{i in range(1,4)}
      \State{tList.append(Thread(target=subAlgorithm2, args=(i,)))}
  \EndFor
  \For{t in tList}
      \State{t.start()}
  \EndFor
  \For{thread in tList}
      \State{thread.join()}
  \EndFor
  \EndProcedure
  \end{algorithmic}
\end{algorithm}

\paragraph{}
La méthode \textit{subAlgorithm2()} s'occupe de partager la liste \textit{people} en 4 (une nouvelle liste
par zone) et selon l'entier reçu de travailler sur l'une des 4 nouvelles listes.

\section{Fonctionnement des bibliothèques utilisés}

\subsection{Bibliothèque threading.Thread}
\paragraph{}
Cette bibliothèque Python permet l'implémentation du parrallélisme grâce à l'utilisation de thread (multithreading).
Le problème est que le GIL (Global Interpreter Lock) réduit fortement l'utilité des threads en Python
car il ne permet l'execution que d'un seul thread natif à la fois. Cela permet d'augmenter fortement les
performances des programmes monothread qui sont beaucoup plus répendu.
\paragraph{}
Il semble donc que le GIL tue le multithreading Python mais pas tout à fait. Il empêche généralement de profiter
de plusieurs coeurs sur une seule machine mais permet de profiter de la latence entre les entrées/sorties.
\paragraph{}
Les scénarios qui vont suivre permettront peut-être de montrer le "faux" parrallélisme du multithreading Python.

\subsection{Librairie threading.Lock}
\paragraph{}
La bibliothèque threading de Python fournie un mécanisme de verrouillage
simple qui permet de synchroniser les threads. Ce système
comprend 2 méthodes. La méthode \textit{acquire()} permet de prendre le vérrou et de 
forcer les autres threads à attendre que celui-ci soit libéré par la méthode 
\textit{release()}.

\section{Analyse des performances}
\paragraph{}
Afin de mesurer les performances des algorithmes, le paramètre -m permet de 
donner le temps moyen que met la foule à sortir du terrain. On reproduit 5 fois
l'algorithme et on supprime les 2 valeurs extrèmes pour obtenir un résultat cohérent.
Ainsi ce résultat n'est pas sensible au temps d'échauffement du processeur et
les performances plus stables.

\subsection{Scénario 0 : thread unique}
\paragraph{}
Voici le tableau des performances du scénario 0 :

\begin{table}[h]
  \centering
  \small
  \begin{tabular}{llllllllll}
    \hline
    \multicolumn{1}{|l|}{\textbf{Taille de la foule}}                     & \multicolumn{1}{l|}{$2^1$} & \multicolumn{1}{l|}{$2^2$} & \multicolumn{1}{l|}{$2^3$} & \multicolumn{1}{l|}{$2^4$} & \multicolumn{1}{l|}{$2^5$} & \multicolumn{1}{l|}{$2^6$} & \multicolumn{1}{l|}{$2^7$} & \multicolumn{1}{l|}{$2^8$} & \multicolumn{1}{l|}{$2^9$} \\ \hline
    \multicolumn{1}{|l|}{\textbf{Temps execution (ms)}} & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{3}  & \multicolumn{1}{l|}{7}  & \multicolumn{1}{l|}{16}  & \multicolumn{1}{l|}{38}  & \multicolumn{1}{l|}{122}  & \multicolumn{1}{l|}{390}  & \multicolumn{1}{l|}{1451}  \\ \hline
    \multicolumn{1}{|l|}{\textbf{Temps CPU (ms)}}    & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{3}  & \multicolumn{1}{l|}{7}  & \multicolumn{1}{l|}{16}  & \multicolumn{1}{l|}{38}  & \multicolumn{1}{l|}{122}  & \multicolumn{1}{l|}{390}  & \multicolumn{1}{l|}{1449}  \\ \hline
                                                                          &                        &                        &                        &                        &                        &                        &                        &                        &                       
    \end{tabular}
  \caption{Performances scénario 0}
  \label{Performances scénario 0}
\end{table}

\paragraph{}
Les résultats ci-dessus montre que le temps d'éxécution de l'algorithme est très similaire au temps d'
utilisation du CPU. Cela n'est pas surprenant car cet algorithme n'utilise pas de parrallélisme. Les 
calculs ne sont réalisés que par un seul thread du processus main.

\subsection{Scénario 1 : une thread par personnes}
\paragraph{}
Voici le tableau des performances du scénario 1 :

\begin{table}[h]
  \centering
  \small
  \begin{tabular}{llllllllll}
    \hline
    \multicolumn{1}{|l|}{\textbf{Taille de la foule}}                     & \multicolumn{1}{l|}{$2^1$} & \multicolumn{1}{l|}{$2^2$} & \multicolumn{1}{l|}{$2^3$} & \multicolumn{1}{l|}{$2^4$} & \multicolumn{1}{l|}{$2^5$} & \multicolumn{1}{l|}{$2^6$} & \multicolumn{1}{l|}{$2^7$} & \multicolumn{1}{l|}{$2^8$} & \multicolumn{1}{l|}{$2^9$} \\ \hline
    \multicolumn{1}{|l|}{\textbf{Temps execution (ms)}} & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{2}  & \multicolumn{1}{l|}{7}  & \multicolumn{1}{l|}{22}  & \multicolumn{1}{l|}{59}  & \multicolumn{1}{l|}{164}  & \multicolumn{1}{l|}{730}  & \multicolumn{1}{l|}{6248}  & \multicolumn{1}{l|}{86753}  \\ \hline
    \multicolumn{1}{|l|}{\textbf{Temps CPU (ms)}}    & \multicolumn{1}{l|}{1}  & \multicolumn{1}{l|}{3}  & \multicolumn{1}{l|}{7}  & \multicolumn{1}{l|}{32}  & \multicolumn{1}{l|}{85}  & \multicolumn{1}{l|}{236}  & \multicolumn{1}{l|}{1012}  & \multicolumn{1}{l|}{8101}  & \multicolumn{1}{l|}{102378}  \\ \hline
                                                                          &                        &                        &                        &                        &                        &                        &                        &                        &                       
    \end{tabular}
  \caption{Performances scénario 1}
  \label{Performances scénario 1}
\end{table}

\paragraph{}
Tout d'abord le temps d'utilisation CPU a fortement augmenté avec ce deuxième algorithme. Il dépasse même
le temps d'éxécution ce qui n'est pas étonnant car celui-ci utilise autant de threads que de personnes il
y a donc des calculs qui s'effectuent en parrallèle. Par contre afin d'assurer la cohérence lors d'une recherche
de déplacement possible et le déplacement en lui même la liste est protégée par un verrou. Comme toutes les
threads tentent d'accéder à la même liste le temps d'attente augmente fortement avec le nombre de personnes.

\subsection{Scénario 2 : 4 threads}
\paragraph{}
Voici le tableau des performances du scénario 2 :

\begin{table}[h]
  \centering
  \small
  \begin{tabular}{llllllllll}
  \hline
  \multicolumn{1}{|l|}{\textbf{Taille de la foule}}                     & \multicolumn{1}{l|}{$2^1$} & \multicolumn{1}{l|}{$2^2$} & \multicolumn{1}{l|}{$2^3$} & \multicolumn{1}{l|}{$2^4$} & \multicolumn{1}{l|}{$2^5$} & \multicolumn{1}{l|}{$2^6$} & \multicolumn{1}{l|}{$2^7$} & \multicolumn{1}{l|}{$2^8$} & \multicolumn{1}{l|}{$2^9$} \\ \hline
  \multicolumn{1}{|l|}{\textbf{Temps execution (ms)}} & \multicolumn{1}{l|}{60}  & \multicolumn{1}{l|}{64}  & \multicolumn{1}{l|}{72}  & \multicolumn{1}{l|}{163}  & \multicolumn{1}{l|}{295}  & \multicolumn{1}{l|}{1099}  & \multicolumn{1}{l|}{1177}  & \multicolumn{1}{l|}{1748}  & \multicolumn{1}{l|}{4379}  \\ \hline
  \multicolumn{1}{|l|}{\textbf{Temps CPU (ms)}}    & \multicolumn{1}{l|}{57}  & \multicolumn{1}{l|}{64}  & \multicolumn{1}{l|}{72}  & \multicolumn{1}{l|}{163}  & \multicolumn{1}{l|}{297}  & \multicolumn{1}{l|}{1102}  & \multicolumn{1}{l|}{1183}  & \multicolumn{1}{l|}{1759}  & \multicolumn{1}{l|}{4424}  \\ \hline
                                                                        &                        &                        &                        &                        &                        &                        &                        &                        &                       
  \end{tabular}
  \caption{Performances scénario 2}
  \label{Performances scénario 2}
\end{table}

\paragraph{}
Pour ce dernier scénario le temps d'utilisation CPU est légèrement supérieur au temps d'éxécution. De 
plus le temps d'éxécution reste bien suprérieur à celui du scénario 1. En effet prendre et rendre un verrou
sont des opérations coûteuses et le décupage en 4 zones ne solutionne pas le problème de bouchon près de la sortie.

\section{Conclusion}
\paragraph{}
Pour conclure, l'utilisation du parrallélisme et du multithreading python n'est pas forcement synonyme
de meilleures performances. En effet les scénarios précédents montrent clairement que assurer la protection
et la cohérence des données entre les différents calculs sont des opérations coûteuses qui impactent lourdement
les performances.
\end{document}